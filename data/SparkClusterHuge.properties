#
# These are properties to be set on the spark cluster
#
#
# prepend to path 
com.lordjoe.distributed.PathPrepend=hdfs://daas/steve/bigones/

spark.mesos.coarse=true
spark.mesos.executor.memoryOverhead=3128

# give executors more memory
spark.executor.memory=12g

# Spark shuffle properties
spark.shuffle.spill=false
spark.shuffle.memoryFraction=0.4
spark.shuffle.consolidateFiles=true
spark.shuffle.file.buffer.kb=1024
spark.reducer.maxMbInFlight=128

spark.storage.memoryFraction=0.3
spark.shuffle.manager=sort
spark.default.parallelism=1200
spark.hadoop.validateOutputSpecs=false

#spark.rdd.compress=true
#spark.shuffle.compress=true
spark.shuffle.spill.compress=true
spark.io.compression.codec=lz4
spark.shuffle.sort.bypassMergeThreshold=100

# try to divide the problem into this many partitions
com.lordjoe.distributed.number_partitions=1200